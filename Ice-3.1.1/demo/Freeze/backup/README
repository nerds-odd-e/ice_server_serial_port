Freeze online backup demo (Linux/Unix only)
===========================================

This demo helps you experiment with Berkeley DB's hot backup
capabilities, and shows how to configure Freeze to support hot
backups.

The client program is very simple: it creates an Int to Long Freeze
map, with 10000 elements. The client uses a transaction to update all
the elements with the current date-time (as a number of milliseconds
since the epoch -- 01/01/1970 at 00:00:00 UTC). It also verifies that
the old values are all the same.

This program runs forever: you need to kill it (e.g., with CTRL-C) to
terminate it.

While the program is running, you can perform a hot backup with the
backup shell script:

% ./backup full

Performs a full backup (both data and log files) in the full
directory.

% ./backup incremental

Performs an incremental backup (only log files) in the the incremental
directory.

The backup script uses the dd program as well as the Berkeley DB
utilities db_archive and db_checkpoint.

The backup shell script runs db_archive before copying any file to get
a list of unused (old) log files. These files are deleted after the
backup is performed. This is a safe way to perform backups, but other
approaches are also possible. Please consult the Berkeley DB
documentation at http://www.sleepycat.com/docs for detailed
information on Berkeley DB hot backups.

Note that the Ice config file (named config) disables the automatic
deletion of old log files:

Freeze.DbEnv.backup.OldLogsAutoDelete=0

and also sets DbPrivate to 0 to allow db_archive to access the db 
environment while the client is running:

Freeze.DbEnv.backup.DbPrivate=0

The db/DB_CONFIG file is used to put the data files and log files in
different sub-directories, which simplifies archiving.

The recover shell script restores either a full backup (the files in
the full directory) or an incremental backup (the files in the full
directory and the files in the incremental directory). Do not run this
script while the client is running.

If your latest backup was incremental, you should use 'recover 
incremental'.

Before doing a recover, you can "corrupt" the main database, for
example by removing the data file (db/data/IntLongMap), or add random
characters to the latest log file.
